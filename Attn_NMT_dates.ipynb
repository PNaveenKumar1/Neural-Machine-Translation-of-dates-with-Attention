{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FixedLocator\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(file_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    args:\n",
    "    file_path: path to the dataset file\n",
    "    \n",
    "    returns:\n",
    "    input_vocab: dictionary containing character to index mapping for input language\n",
    "    output_vocab: dictionary containing character to index mapping for output language\n",
    "    input_vocab_inv: dictionary containing index to character mapping for input language\n",
    "    output_vocab_inv: dictionary containing index to character mapping for output language\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    input_vocab = defaultdict(lambda:len(input_vocab))\n",
    "    output_vocab = defaultdict(lambda:len(output_vocab))\n",
    "    \n",
    "    input_vocab['<PAD>'] = 0\n",
    "    input_vocab['<UNK>'] = 1\n",
    "    output_vocab['<PAD>'] = 0\n",
    "    output_vocab['<UNK>'] = 1\n",
    "    \n",
    "    output_vocab['<SOS>'] = 2\n",
    "    output_vocab['<EOS>'] = 3\n",
    "    \n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            input_sent, output_sent = line.strip().split(',')\n",
    "            input_sent = input_sent.strip().strip(\"'\")\n",
    "            output_sent = output_sent.strip().strip(\"'\")\n",
    "            \n",
    "            for char in input_sent:\n",
    "                input_vocab[char]\n",
    "                \n",
    "            for char in output_sent:\n",
    "                output_vocab[char]\n",
    "                \n",
    "                \n",
    "    input_vocab = dict(input_vocab)\n",
    "    output_vocab = dict(output_vocab)\n",
    "    \n",
    "    input_vocab_inv = {v:k for k,v in input_vocab.items()}\n",
    "    output_vocab_inv = {v:k for k,v in output_vocab.items()}\n",
    "    \n",
    "    return input_vocab, output_vocab, input_vocab_inv, output_vocab_inv\n",
    "\n",
    "\n",
    "# Use BPE tokenization to build the vocabulary\n",
    "\n",
    "def get_stats(vocab):\n",
    "    pairs = defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "    return pairs\n",
    "\n",
    "def merge_vocab(pair, v_in):\n",
    "    import re\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateTranslationDataset(Dataset):\n",
    "    def __init__(self, file_path,input_vocab, output_vocab,max_input_len, max_output_len=10):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "        file_path: path to the data file\n",
    "        input_vocab: input vocabulary\n",
    "        output_vocab: output vocabulary\n",
    "        max_input_len: maximum length of input sequence\n",
    "        max_output_len: maximum length of output sequence is always 10 because ouput format is YYYY-MM-DD\n",
    "        \"\"\"\n",
    "        \n",
    "        self.input_vocab = input_vocab  \n",
    "        self.output_vocab = output_vocab\n",
    "        self.max_input_len = max_input_len\n",
    "        self.max_output_len = max_output_len\n",
    "        self.data = self.load_data(file_path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx][0]), torch.tensor(self.data[idx][1])\n",
    "    \n",
    "    def load_data(self, file_path):\n",
    "        data = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                input_sent, output_sent = line.strip().split(',')\n",
    "                input_sent = input_sent.strip().strip(\"'\")\n",
    "                output_sent = output_sent.strip().strip(\"'\")\n",
    "                \n",
    "                input_ids = [self.input_vocab.get(char, self.input_vocab['<UNK>']) for char in input_sent][:self.max_input_len]\n",
    "                output_ids = [self.output_vocab.get(char, self.output_vocab['<UNK>']) for char in output_sent][:self.max_output_len]\n",
    "                \n",
    "                # padding on left side\n",
    "                input_ids = [self.input_vocab['<PAD>']]*(self.max_input_len - len(input_ids)) + input_ids\n",
    "                output_ids = [self.output_vocab['<PAD>']]*(self.max_output_len - len(output_ids)) + output_ids\n",
    "                \n",
    "                output_ids = [self.output_vocab['<SOS>']] + output_ids + [self.output_vocab['<EOS>']]\n",
    "                \n",
    "                data.append((input_ids, output_ids))\n",
    "                \n",
    "        return data\n",
    "                \n",
    "               \n",
    "                \n",
    "def get_dataloader(file_path, input_vocab, output_vocab, max_input_len, max_output_len, batch_size):\n",
    "    dataset = DateTranslationDataset(file_path, input_vocab, output_vocab, max_input_len, max_output_len)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "# # Lets test the dataloader\n",
    "# input_vocab, output_vocab, _, _ = build_vocab('Data/train.txt')\n",
    "# dataloader = get_dataloader('Data/train.txt', input_vocab, output_vocab, 20, 10, 2)\n",
    "\n",
    "# for input_batch, output_batch in dataloader:\n",
    "    \n",
    "#     print('Input Batch Shape:', input_batch.shape)\n",
    "#     print('Output Batch Shape:', output_batch.shape)\n",
    "    \n",
    "#     # Lets print the first batch\n",
    "#     print('Input Batch:', input_batch)\n",
    "    \n",
    "#     print('Output Batch:', output_batch)\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_vocab_size, emb_dim, enc_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_vocab_size, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True, batch_first = True)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        embedded = self.embedding(x)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1) # concatenate the hidden states of the forward and backward RNNs\n",
    "        return outputs, hidden\n",
    "    \n",
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Use Bahdanau Attention formula is  \n",
    "    e_ij = v^T * tanh(W_a * s_{i-1} + U_a * h_j) \n",
    "    where s_{i-1} is the previous hidden state of the decoder and h_j is the hidden state of the encoder\n",
    "    \n",
    "    alpha_ij = softmax(e_ij)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.W_a = nn.Linear(dec_hid_dim, dec_hid_dim)\n",
    "        self.U_a = nn.Linear(enc_hid_dim*2, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "            \n",
    "            # hidden = [batch_size, dec_hid_dim]\n",
    "            # encoder_outputs = [batch_size, seq_len, enc_hid_dim*2]\n",
    "                        \n",
    "            projected_hidden = self.W_a(hidden.unsqueeze(1)) # [batch_size, 1, dec_hid_dim]\n",
    "        \n",
    "            energy = (torch.tanh(projected_hidden + self.U_a(encoder_outputs))) # [batch_size, seq_len, dec_hid_dim]\n",
    "            \n",
    "            \n",
    "            attention = self.v(energy).squeeze(2) # [batch_size, seq_len]\n",
    "            \n",
    "            attention_weights = torch.softmax(attention, dim = 1) # [batch_size, seq_len]\n",
    "            \n",
    "            return attention_weights\n",
    "\n",
    "class ConcatAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Use Concatenative Attention formula is\n",
    "    e_ij = v^T * tanh(W_a *[s_{i-1}; h_j])\n",
    "    where s_{i-1} is the previous hidden state of the decoder and h_j is the hidden state of the encoder\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.W_a = nn.Linear((enc_hid_dim*2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "            \n",
    "            # hidden = [batch_size, dec_hid_dim]\n",
    "            # encoder_outputs = [batch_size, seq_len, enc_hid_dim*2]\n",
    "            \n",
    "            hidden = hidden.unsqueeze(1).repeat(1, encoder_outputs.shape[1], 1) # [batch_size, seq_len, dec_hid_dim]\n",
    "            \n",
    "            energy = torch.tanh(self.W_a(torch.cat((hidden, encoder_outputs), dim = 2))) # [batch_size, seq_len, dec_hid_dim]\n",
    "            \n",
    "            attention = self.v(energy).squeeze(2) # [batch_size, seq_len]\n",
    "            \n",
    "            attention_weights = torch.softmax(attention, dim = 1) # [batch_size, seq_len]\n",
    "            \n",
    "            return attention_weights\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Decoder with attention mechanism\n",
    "    \"\"\"\n",
    "    def __init__(self, output_vocab_size, emb_dim, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        self.attention = BahdanauAttention(enc_hid_dim, dec_hid_dim)\n",
    "        # self.concat_attention = ConcatAttention(enc_hid_dim, dec_hid_dim)\n",
    "        self.embedding = nn.Embedding(output_vocab_size, emb_dim)\n",
    "        self.rnn = nn.GRU((enc_hid_dim*2) + emb_dim, dec_hid_dim, batch_first = True) # we are passing the context vector and the embedded token as input by concatenating them\n",
    "        self.fc = nn.Linear(dec_hid_dim, output_vocab_size) \n",
    "        \n",
    "        \n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "            \n",
    "            # x = [batch_size]\n",
    "            # hidden = [batch_size, dec_hid_dim]\n",
    "            # encoder_outputs = [batch_size, seq_len, enc_hid_dim*2]\n",
    "            \n",
    "            x = x.unsqueeze(1) # [batch_size, 1]\n",
    "            embedded = self.embedding(x) # [batch_size, 1, emb_dim]\n",
    "            \n",
    "            attention_weights = self.attention(hidden, encoder_outputs) # [batch_size, seq_len]\n",
    "            # attention_weights = self.concat_attention(hidden, encoder_outputs) # [batch_size, seq_len]\n",
    "            attention_weights = attention_weights.unsqueeze(1) # [batch_size, 1, seq_len]\n",
    "            \n",
    "            context_vector = torch.bmm(attention_weights, encoder_outputs) # [batch_size, 1, enc_hid_dim*2]\n",
    "            \n",
    "            rnn_input = torch.cat((embedded, context_vector), dim = 2) # [batch_size, 1, (enc_hid_dim*2) + emb_dim]\n",
    "            \n",
    "            output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0)) # output = [batch_size, 1, dec_hid_dim], hidden = [1, batch_size, dec_hid_dim]\n",
    "            \n",
    "            prediction = self.fc(output.squeeze(1)) # [batch_size, output_vocab_size]\n",
    "            \n",
    "            return prediction, hidden.squeeze(0), attention_weights.squeeze(1)\n",
    "            \n",
    "        \n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, input, target, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        # input = [batch_size, seq_len]\n",
    "        # target = [batch_size, seq_len]\n",
    "        \n",
    "        batch_size = input.shape[0]\n",
    "        target_len = target.shape[1]\n",
    "        target_vocab_size = self.decoder.output_vocab_size\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, target_len-1, target_vocab_size).to(self.device)\n",
    "        \n",
    "        attention_scores = torch.zeros(batch_size, target_len-1, input.shape[1]).to(self.device)\n",
    "        \n",
    "        \n",
    "        encoder_outputs, hidden = self.encoder(input) \n",
    "        \n",
    "        x = target[:,0] # <SOS> token\n",
    "        \n",
    "        for t in range(1, target_len):\n",
    "            \n",
    "            output, hidden, attention_weights = self.decoder(x, hidden, encoder_outputs)\n",
    "            \n",
    "            attention_scores[:,t-1] = attention_weights\n",
    "            \n",
    "            outputs[:,t-1] = output \n",
    "            \n",
    "            teacher_force = torch.rand(1) < teacher_forcing_ratio\n",
    "            \n",
    "            top1 = output.argmax(1)\n",
    "            \n",
    "            # x = target[:,t] if teacher_force else top1 # if teacher_force is True, we use the actual target token, else we use the predicted token\n",
    "            x = top1 # we are not using teacher forcing\n",
    "        return outputs, attention_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,trainloader,epochs,optimizer,criterion,device):\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        print('*'*20 + f'Epoch {epoch+1}' + '*'*20)\n",
    "        for src,tgt in trainloader:\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output,_ = model(src,tgt)\n",
    "            \n",
    "            tgt = tgt[:,1:]\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.reshape(-1,output_dim)\n",
    "            tgt = tgt.reshape(-1)\n",
    "    \n",
    "            loss = criterion(output,tgt)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f'Epoch: {epoch+1:02}')\n",
    "        \n",
    "        \n",
    "        print(f'Train Loss: {epoch_loss/len(trainloader):.3f}')\n",
    "        print(f'Validation Loss: {evaluate(model,validloader,criterion,device):.3f}')\n",
    "        \n",
    "    # Save the model in Models folder\n",
    "    torch.save(model.state_dict(), '../Assignment2/Models/model4.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,validloader,criterion,device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    accuracy = 0 \n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for src,tgt in validloader:\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            output,_ = model(src,tgt,0) #turn off teacher forcing  \n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.reshape(-1,output_dim)\n",
    "            tgt = tgt[:,1:]\n",
    "            tgt = tgt.reshape(-1)\n",
    "            loss = criterion(output,tgt)\n",
    "            \n",
    "           # check if all the characters are correct , if yes then increment the accuracy\n",
    "            # print(torch.argmax(output,dim=1).shape,tgt.shape)\n",
    "            accuracy += torch.sum(torch.argmax(output,dim=1) == tgt).item()\n",
    "            total += tgt.shape[0]\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    print(f'Validation Accuracy: {accuracy/total:.3f}')\n",
    "        \n",
    "    return epoch_loss/len(validloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,src,src_vocab,tgt_vocab,tgt_inv_vocab,max_len,device):\n",
    "    \n",
    " \n",
    "    src = torch.tensor([src_vocab.get(char,src_vocab['<UNK>']) for char in src]).unsqueeze(0).to(device)\n",
    "    \n",
    "    tgt = [tgt_vocab['<SOS>']]+[tgt_vocab['<PAD>']]*max_len+[tgt_vocab['<EOS>']]\n",
    "    tgt = torch.tensor(tgt).unsqueeze(0).to(device)\n",
    "    \n",
    "    outputs,attention_scores = model(src,tgt,0)\n",
    "    \n",
    "    outputs = outputs.squeeze(0)\n",
    "    \n",
    "    print(outputs.shape)\n",
    "    decoder_outputs = []\n",
    "    for output in outputs:\n",
    "            output = output.argmax(0).item()\n",
    "            \n",
    "            if output == tgt_vocab['<EOS>']:\n",
    "                break\n",
    "            decoder_outputs.append(tgt_inv_vocab[output])\n",
    "            # decoder_outputs.append(output)\n",
    "    # return \"\".join(decoder_outputs)\n",
    "    return decoder_outputs,attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab, output_vocab, input_vocab_inv,output_vocab_inv = build_vocab('../Assignment2/Data/Assignment2_train.txt')\n",
    "# /data2/home/kpnaveen/DLNLP/Assignment2/Data/Assignment2_train.txt\n",
    "input_vocab_size = len(input_vocab)\n",
    "output_vocab_size = len(output_vocab)\n",
    "max_input_len = 16\n",
    "max_output_len = 10\n",
    "batch_size = 32\n",
    "embedding_size = 128 # 128 used for model with accuracy 0.88\n",
    "enc_hidden_size = 128  #use 128 for model with accuracy 0.88\n",
    "dec_hidden_size = 2*128 #use 2*128 for model with accuracy 0.88\n",
    "learning_rate = 0.0015\n",
    "num_epochs = 3 \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trainloader = get_dataloader('../Assignment2/Data/Assignment2_train.txt', input_vocab, output_vocab, max_input_len, max_output_len, batch_size)\n",
    "validloader = get_dataloader('../Assignment2/Data/Assignment2_validation.txt', input_vocab, output_vocab, max_input_len, max_output_len, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_vocab_size, embedding_size, enc_hidden_size)\n",
    "decoder = Decoder(output_vocab_size, embedding_size, enc_hidden_size, dec_hidden_size)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = output_vocab['<PAD>'])\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Epoch 1********************\n",
      "Epoch: 01\n",
      "Train Loss: 0.241\n",
      "Validation Accuracy: 0.947\n",
      "Validation Loss: 0.135\n",
      "********************Epoch 2********************\n",
      "Epoch: 02\n",
      "Train Loss: 0.137\n",
      "Validation Accuracy: 0.948\n",
      "Validation Loss: 0.133\n",
      "********************Epoch 3********************\n",
      "Epoch: 03\n",
      "Train Loss: 0.137\n",
      "Validation Accuracy: 0.948\n",
      "Validation Loss: 0.134\n"
     ]
    }
   ],
   "source": [
    "train(model,trainloader,num_epochs,optimizer,criterion,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_876201/2486227211.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Assignment2/Models/model4.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../Assignment2/Models/model4.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_visualization(model,src,input_vocab,output_vocab,output_vocab_inv,max_output_len,device):\n",
    "    outputs,attention_scores = predict(model,src,input_vocab,output_vocab,output_vocab_inv,max_output_len,device)\n",
    "    src_tokens = [char for char in src]\n",
    "    tgt_tokens = outputs\n",
    "    \n",
    "    #convert attention scores to numpy\n",
    "    \n",
    "    attention_scores = attention_scores.squeeze(0).cpu().detach().numpy() # [tgt_len, src_len]\n",
    "    \n",
    "   \n",
    "    \n",
    "    print('Source:', src)\n",
    "    print('Predicted:', \"\".join(outputs))\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12,12))\n",
    "    cax=ax.matshow(attention_scores, cmap='bone')\n",
    "    \n",
    "    ax.set_xticks(np.arange(len(src_tokens)))\n",
    "    ax.set_yticks(np.arange(len(tgt_tokens)))\n",
    "  \n",
    "    \n",
    "    ax.set_xticklabels(src_tokens, rotation=90,)\n",
    "    ax.set_yticklabels(tgt_tokens)\n",
    "    \n",
    "    ax.set_xlabel('Input Sequence')\n",
    "    ax.set_ylabel('Output Sequence')\n",
    "    \n",
    "    fig.colorbar(cax)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    #save the plot\n",
    "    \n",
    "    plt.savefig('../Assignment2/plots/attention4.png')\n",
    "    \n",
    "    \n",
    "\n",
    "# attention_visualization(model,'29 March 2022',input_vocab,output_vocab,output_vocab_inv,max_output_len,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_vocab, output_vocab, input_vocab_inv,output_vocab_inv = build_vocab('../Assignment2/Data/Assignment2_train.txt')\n",
    "# input_vocab_size = len(input_vocab)\n",
    "# output_vocab_size = len(output_vocab)\n",
    "# max_input_len = 20\n",
    "# max_output_len = 10\n",
    "# batch_size = 32\n",
    "# embedding_size = 128\n",
    "# enc_hidden_size = 128\n",
    "# dec_hidden_size = 2*128\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# encoder = Encoder(input_vocab_size, embedding_size, enc_hidden_size)\n",
    "# decoder = Decoder(output_vocab_size, embedding_size, enc_hidden_size, dec_hidden_size)\n",
    "# model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_876201/2486227211.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Assignment2/Models/model4.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../Assignment2/Models/model4.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now load validation.txt  where each line is a pair of input and output date separated by a comma, so give input to the predict function and compare whether the output is correct or not\n",
    "def predict(model,src,src_vocab,tgt_vocab,tgt_inv_vocab,max_len,device):\n",
    "    \n",
    " \n",
    "    src = torch.tensor([src_vocab.get(char,src_vocab['<UNK>']) for char in src]).unsqueeze(0).to(device)\n",
    "    \n",
    "    tgt = [tgt_vocab['<SOS>']]+[tgt_vocab['<PAD>']]*max_len+[tgt_vocab['<EOS>']]\n",
    "    tgt = torch.tensor(tgt).unsqueeze(0).to(device)\n",
    "    \n",
    "    outputs,attention_scores = model(src,tgt,0)\n",
    "    \n",
    "    outputs = outputs.squeeze(0)\n",
    "   \n",
    "    decoder_outputs = []\n",
    "    for output in outputs:\n",
    "            output = output.argmax(0).item()\n",
    "            \n",
    "            if output == tgt_vocab['<EOS>']:\n",
    "                break\n",
    "            decoder_outputs.append(tgt_inv_vocab[output])\n",
    "            # decoder_outputs.append(output)\n",
    "    return \"\".join(decoder_outputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed\n"
     ]
    }
   ],
   "source": [
    "actual_outputs = []\n",
    "predicted_outputs = []\n",
    "\n",
    "with open('../Assignment2/Data/Assignment2_validation.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        input_sent, output_sent = line.strip().split(',')\n",
    "        input_sent = input_sent.strip().strip(\"'\")\n",
    "        output_sent = output_sent.strip().strip(\"'\")\n",
    "        \n",
    "        output = predict(model, input_sent, input_vocab, output_vocab, output_vocab_inv, max_output_len, device)\n",
    "        \n",
    "        actual_outputs.append(output_sent)\n",
    "        predicted_outputs.append(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "print('All tests passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these actual and  predicted in  a txt file\n",
    "with open('../Assignment2/Data/predictions.txt', 'w') as file:\n",
    "    for actual, predicted in zip(actual_outputs, predicted_outputs):\n",
    "        file.write(actual + ',' + predicted + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excat matches  3842\n",
      "Less than 10  3\n"
     ]
    }
   ],
   "source": [
    "def calculate_all_errors(actual_outputs, predicted_outputs):\n",
    "    \n",
    "    exact_match_error = 0\n",
    "    mismatch_error = 0\n",
    "    position_errors = [0]*10\n",
    "    \n",
    "    less_than_10 = 0\n",
    "    \n",
    "    for actual, predicted in zip(actual_outputs, predicted_outputs):\n",
    "        \n",
    "        if len(actual) != 10 or len(predicted) != 10:\n",
    "            less_than_10 += 1\n",
    "            continue\n",
    "        \n",
    "        exact_match_error += 1 if actual == predicted else 0\n",
    "        for i in range(10):\n",
    "            mismatch_error += 1 if actual[i] != predicted[i] else 0\n",
    "            position_errors[i] += 1 if actual[i] != predicted[i] else 0\n",
    "            \n",
    "    highest_error = position_errors.index(max(position_errors)) + 1\n",
    "    lowest_error = position_errors.index(min(position_errors)) + 1\n",
    "    \n",
    "    print(\"Excat matches \", exact_match_error)\n",
    "    print(\"Less than 10 \", less_than_10)\n",
    "        \n",
    "    exact_match_error = (exact_match_error/len(actual_outputs))*100\n",
    "    mismatch_error = (mismatch_error/(len(actual_outputs)*10))*100\n",
    "    \n",
    "    return exact_match_error, mismatch_error, highest_error, lowest_error\n",
    "\n",
    "exact_match_error, mismatch_error, highest_error, lowest_error = calculate_all_errors(actual_outputs, predicted_outputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Error: 96.05\n",
      "Mismatch Error: 0.49750000000000005\n",
      "Highest Error: 2\n",
      "Lowest Error: 5\n"
     ]
    }
   ],
   "source": [
    "print('Exact Match Error:', exact_match_error)\n",
    "print('Mismatch Error:', mismatch_error)\n",
    "print('Highest Error:', highest_error)\n",
    "print('Lowest Error:', lowest_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDateTranslationDataset(Dataset):\n",
    "    def __init__(self, file_path,input_vocab, output_vocab,max_input_len, max_output_len=10):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "        file_path: path to the data file\n",
    "        input_vocab: input vocabulary\n",
    "        output_vocab: output vocabulary\n",
    "        max_input_len: maximum length of input sequence\n",
    "        max_output_len: maximum length of output sequence is always 10 because ouput format is YYYY-MM-DD\n",
    "        \"\"\"\n",
    "        \n",
    "        self.input_vocab = input_vocab  \n",
    "        self.output_vocab = output_vocab\n",
    "        self.max_input_len = max_input_len\n",
    "        self.max_output_len = max_output_len\n",
    "        self.data = self.load_data(file_path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx][0]), torch.tensor(self.data[idx][1])\n",
    "    \n",
    "    def load_data(self, file_path):\n",
    "        data = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                # input_sent, output_sent = line.strip().split(',')\n",
    "                input_sent = line.strip()\n",
    "                input_sent = input_sent.strip().strip(\"'\")\n",
    "                # output_sent = output_sent.strip().strip(\"'\")\n",
    "                \n",
    "                input_ids = [self.input_vocab.get(char, self.input_vocab['<UNK>']) for char in input_sent][:self.max_input_len]\n",
    "                # output_ids = [self.output_vocab.get(char, self.output_vocab['<UNK>']) for char in output_sent][:self.max_output_len]\n",
    "                \n",
    "                # padding on left side\n",
    "                input_ids = [self.input_vocab['<PAD>']]*(self.max_input_len - len(input_ids)) + input_ids\n",
    "                # output_ids = [self.output_vocab['<PAD>']]*(self.max_output_len - len(output_ids)) + output_ids\n",
    "                \n",
    "                # output_ids = [self.output_vocab['<SOS>']] + output_ids + [self.output_vocab['<EOS>']]\n",
    "                \n",
    "                # data.append((input_ids, output_ids))\n",
    "                data.append((input_ids))\n",
    "                \n",
    "        return data\n",
    "                \n",
    "               \n",
    "                \n",
    "def get_test_dataloader(file_path, input_vocab, output_vocab, max_input_len, max_output_len, batch_size):\n",
    "    dataset = TestDateTranslationDataset(file_path, input_vocab, output_vocab, max_input_len, max_output_len)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size,shuffle=False)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = get_test_dataloader('../Assignment2/Data/Assignment2_Test.txt', input_vocab, output_vocab, max_input_len, max_output_len, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed\n"
     ]
    }
   ],
   "source": [
    "test_actual_outputs = []\n",
    "test_predicted_outputs = []\n",
    "\n",
    "with open('../Assignment2/Data/Assignment2_Test.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # input_sent, output_sent = line.strip().split(',')\n",
    "        input_sent = line.strip()\n",
    "        input_sent = input_sent.strip().strip(\"'\")\n",
    "        # output_sent = output_sent.strip().strip(\"'\")\n",
    "        \n",
    "        output = predict(model, input_sent, input_vocab, output_vocab, output_vocab_inv, max_output_len, device)\n",
    "        \n",
    "        test_actual_outputs.append(output_sent)\n",
    "        test_predicted_outputs.append(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "print('All tests passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these actual and  predicted in  a txt file\n",
    "with open('../Assignment2/Data/test_predictions.txt', 'w') as file:\n",
    "    for predicted in test_predicted_outputs:\n",
    "        file.write(predicted+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the file and make list of the test actual outputs\n",
    "test_actual_outputs = []\n",
    "with open('../Assignment2/Data/Assignment2_LabeledTestSet.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # test_actual_outputs.append(line.strip())\n",
    "        input_sent, output_sent = line.strip().split(',')\n",
    "        input_sent = input_sent.strip().strip(\"'\")\n",
    "        output_sent = output_sent.strip().strip(\"'\")\n",
    "\n",
    "        #make list of input sentences and output sentences\n",
    "        test_actual_outputs.append(output_sent)\n",
    "        \n",
    "        # with open('../Assignment2/Data/Assignment2_validation.txt', 'r') as file:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1733-08-14',\n",
       " '1625-11-24',\n",
       " '1723-01-24',\n",
       " '1551-11-18',\n",
       " '1591-08-10',\n",
       " '2064-11-03',\n",
       " '1554-06-21',\n",
       " '1661-12-29',\n",
       " '1919-12-15',\n",
       " '1727-05-08',\n",
       " '2064-02-08',\n",
       " '1705-08-27',\n",
       " '1572-05-28',\n",
       " '1860-11-07',\n",
       " '1761-10-19',\n",
       " '1816-03-30',\n",
       " '1795-08-28',\n",
       " '1793-12-21',\n",
       " '1980-03-29',\n",
       " '1706-08-17',\n",
       " '1775-12-11',\n",
       " '1899-02-20',\n",
       " '2035-09-12',\n",
       " '1893-08-24',\n",
       " '1897-07-31',\n",
       " '1624-04-28',\n",
       " '1562-12-30',\n",
       " '1580-05-02',\n",
       " '1665-01-01',\n",
       " '1861-09-22',\n",
       " '1872-01-01',\n",
       " '1992-04-12',\n",
       " '1885-10-20',\n",
       " '1649-05-20',\n",
       " '1600-08-11',\n",
       " '1644-09-22',\n",
       " '1572-05-21',\n",
       " '1820-06-25',\n",
       " '2055-05-18',\n",
       " '2057-11-18',\n",
       " '1946-11-17',\n",
       " '1658-05-25',\n",
       " '1740-09-03',\n",
       " '1986-11-22',\n",
       " '1950-03-24',\n",
       " '1864-03-29',\n",
       " '1658-01-26',\n",
       " '1939-03-07',\n",
       " '1793-05-27',\n",
       " '1845-12-09',\n",
       " '1806-09-05',\n",
       " '1648-04-13',\n",
       " '1702-04-08',\n",
       " '2011-08-28',\n",
       " '1956-07-12',\n",
       " '1521-11-24',\n",
       " '1880-09-07',\n",
       " '1568-08-11',\n",
       " '1925-10-24',\n",
       " '1601-07-07',\n",
       " '1952-01-07',\n",
       " '2057-04-08',\n",
       " '1825-04-20',\n",
       " '1674-09-05',\n",
       " '1875-07-14',\n",
       " '1993-02-13',\n",
       " '1764-06-18',\n",
       " '1649-09-06',\n",
       " '1704-10-04',\n",
       " '1975-11-02',\n",
       " '1691-12-21',\n",
       " '1887-03-11',\n",
       " '1608-12-14',\n",
       " '1889-03-17',\n",
       " '1811-07-14',\n",
       " '2060-03-06',\n",
       " '1689-10-27',\n",
       " '1723-06-20',\n",
       " '1655-01-14',\n",
       " '1712-11-11',\n",
       " '1729-05-16',\n",
       " '1827-12-07',\n",
       " '1553-04-29',\n",
       " '1566-07-21',\n",
       " '1914-09-07',\n",
       " '1696-03-11',\n",
       " '1740-10-18',\n",
       " '1763-09-30',\n",
       " '1554-06-23',\n",
       " '1839-07-08',\n",
       " '1750-01-15',\n",
       " '1649-04-24',\n",
       " '1860-05-03',\n",
       " '1977-06-18',\n",
       " '1963-03-05',\n",
       " '1588-09-18',\n",
       " '1690-09-09',\n",
       " '1950-12-24',\n",
       " '2060-01-30',\n",
       " '1637-08-18',\n",
       " '1579-05-25',\n",
       " '1528-05-19',\n",
       " '1733-01-15',\n",
       " '2054-11-20',\n",
       " '1684-08-16',\n",
       " '1555-03-18',\n",
       " '1601-09-22',\n",
       " '1925-09-13',\n",
       " '1732-12-04',\n",
       " '1545-05-17',\n",
       " '1888-04-14',\n",
       " '1618-07-17',\n",
       " '1665-01-13',\n",
       " '1964-02-18',\n",
       " '1699-10-11',\n",
       " '2038-06-21',\n",
       " '1847-05-25',\n",
       " '1730-05-08',\n",
       " '1609-12-06',\n",
       " '1708-07-11',\n",
       " '1866-01-04',\n",
       " '1746-07-18',\n",
       " '1777-06-26',\n",
       " '1620-03-27',\n",
       " '1635-02-06',\n",
       " '1590-11-14',\n",
       " '1725-03-28',\n",
       " '1697-04-03',\n",
       " '1796-02-07',\n",
       " '1657-01-10',\n",
       " '1577-05-19',\n",
       " '1873-02-07',\n",
       " '1999-03-25',\n",
       " '2033-07-04',\n",
       " '1624-01-03',\n",
       " '1688-04-09',\n",
       " '1829-09-30',\n",
       " '1691-08-04',\n",
       " '1940-12-02',\n",
       " '1563-10-29',\n",
       " '1621-04-22',\n",
       " '1603-07-08',\n",
       " '1885-01-02',\n",
       " '2060-03-15',\n",
       " '1871-04-02',\n",
       " '1786-03-31',\n",
       " '1801-10-23',\n",
       " '1961-01-09',\n",
       " '1740-04-03',\n",
       " '1628-08-07',\n",
       " '2021-07-19',\n",
       " '1974-02-01',\n",
       " '1569-09-04',\n",
       " '1933-08-08',\n",
       " '1959-09-27',\n",
       " '1882-09-27',\n",
       " '2016-01-03',\n",
       " '1792-12-19',\n",
       " '1969-10-30',\n",
       " '1917-01-13',\n",
       " '1704-08-17',\n",
       " '1896-02-17',\n",
       " '1528-02-21',\n",
       " '1914-10-20',\n",
       " '1696-03-26',\n",
       " '1888-07-28',\n",
       " '1948-05-21',\n",
       " '1586-01-28',\n",
       " '1685-06-23',\n",
       " '1791-02-15',\n",
       " '1968-07-23',\n",
       " '1538-08-17',\n",
       " '1914-04-13',\n",
       " '1686-09-11',\n",
       " '1690-03-02',\n",
       " '1785-11-09',\n",
       " '1578-08-19',\n",
       " '1727-03-03',\n",
       " '1925-06-23',\n",
       " '2068-12-25',\n",
       " '1612-10-01',\n",
       " '2016-05-01',\n",
       " '1689-03-18',\n",
       " '2055-06-24',\n",
       " '1638-11-01',\n",
       " '1731-12-02',\n",
       " '1622-01-04',\n",
       " '1996-07-28',\n",
       " '2027-04-14',\n",
       " '1687-10-05',\n",
       " '1707-10-16',\n",
       " '1702-06-20',\n",
       " '1542-06-30',\n",
       " '1774-05-02',\n",
       " '1793-09-18',\n",
       " '1959-10-22',\n",
       " '1756-12-14',\n",
       " '2065-07-21',\n",
       " '1978-07-30',\n",
       " '1735-03-30',\n",
       " '1940-07-28',\n",
       " '2049-01-24',\n",
       " '1949-09-22',\n",
       " '1557-10-30',\n",
       " '1701-10-25',\n",
       " '1621-05-15',\n",
       " '1710-06-09',\n",
       " '1813-08-04',\n",
       " '1571-07-02',\n",
       " '1905-02-25',\n",
       " '1986-08-10',\n",
       " '1586-06-07',\n",
       " '2066-07-04',\n",
       " '2042-05-12',\n",
       " '1804-01-20',\n",
       " '1881-04-04',\n",
       " '1630-01-04',\n",
       " '1846-10-25',\n",
       " '1889-04-29',\n",
       " '1595-04-26',\n",
       " '1782-12-07',\n",
       " '1820-07-17',\n",
       " '1797-11-26',\n",
       " '1773-10-11',\n",
       " '1626-12-12',\n",
       " '2032-04-17',\n",
       " '2057-07-02',\n",
       " '1581-08-09',\n",
       " '1716-02-04',\n",
       " '1787-06-28',\n",
       " '1554-08-03',\n",
       " '1850-11-16',\n",
       " '2047-01-03',\n",
       " '1830-08-26',\n",
       " '1988-11-01',\n",
       " '1761-06-13',\n",
       " '1743-09-06',\n",
       " '1662-08-16',\n",
       " '1624-01-19',\n",
       " '1683-11-25',\n",
       " '1550-10-19',\n",
       " '1678-04-04',\n",
       " '1962-08-25',\n",
       " '1820-11-30',\n",
       " '1835-05-01',\n",
       " '1816-02-20',\n",
       " '1566-08-24',\n",
       " '1578-01-22',\n",
       " '1720-11-03',\n",
       " '2020-04-07',\n",
       " '1550-04-30',\n",
       " '2015-08-13',\n",
       " '1962-12-13',\n",
       " '1698-02-15',\n",
       " '1616-01-06',\n",
       " '1753-03-23',\n",
       " '1975-11-20',\n",
       " '1656-05-10',\n",
       " '2033-12-13',\n",
       " '1657-12-31',\n",
       " '1821-11-02',\n",
       " '1855-07-05',\n",
       " '1979-05-15',\n",
       " '2050-11-08',\n",
       " '2057-04-09',\n",
       " '1970-10-14',\n",
       " '1747-01-08',\n",
       " '1954-06-09',\n",
       " '1696-08-01',\n",
       " '1536-03-30',\n",
       " '1939-11-30',\n",
       " '1605-12-25',\n",
       " '1920-09-30',\n",
       " '2021-12-01',\n",
       " '1851-04-30',\n",
       " '2070-01-27',\n",
       " '1783-03-25',\n",
       " '1813-10-31',\n",
       " '1848-06-11',\n",
       " '1804-09-16',\n",
       " '1741-11-02',\n",
       " '1717-05-23',\n",
       " '1525-10-30',\n",
       " '1978-03-09',\n",
       " '1558-12-06',\n",
       " '1951-07-27',\n",
       " '1633-02-26',\n",
       " '1637-04-24',\n",
       " '1999-01-02',\n",
       " '1945-09-14',\n",
       " '1717-01-29',\n",
       " '1539-02-21',\n",
       " '1857-01-30',\n",
       " '1975-05-21',\n",
       " '1745-09-01',\n",
       " '1960-03-14',\n",
       " '1611-07-20',\n",
       " '1996-08-17',\n",
       " '2054-08-03',\n",
       " '1612-05-10',\n",
       " '1559-02-14',\n",
       " '1628-04-14',\n",
       " '1576-04-18',\n",
       " '1894-04-25',\n",
       " '1771-06-14',\n",
       " '1837-02-19',\n",
       " '1528-05-23',\n",
       " '1926-02-16',\n",
       " '2031-06-23',\n",
       " '1901-01-10',\n",
       " '1614-01-08',\n",
       " '1534-01-23',\n",
       " '1691-10-20',\n",
       " '1731-08-13',\n",
       " '1867-08-22',\n",
       " '1549-12-12',\n",
       " '1842-02-20',\n",
       " '1529-04-27',\n",
       " '1521-12-08',\n",
       " '1673-07-21',\n",
       " '1690-12-22',\n",
       " '1728-09-05',\n",
       " '1838-01-03',\n",
       " '1669-08-08',\n",
       " '1814-01-15',\n",
       " '1843-10-20',\n",
       " '1829-07-17',\n",
       " '2026-09-28',\n",
       " '1834-05-03',\n",
       " '1695-07-02',\n",
       " '1619-05-08',\n",
       " '1561-07-23',\n",
       " '1952-12-14',\n",
       " '1525-04-04',\n",
       " '1767-09-14',\n",
       " '1937-03-27',\n",
       " '1553-02-19',\n",
       " '1988-02-28',\n",
       " '1874-09-10',\n",
       " '1654-05-01',\n",
       " '1594-02-06',\n",
       " '2022-08-04',\n",
       " '1692-11-21',\n",
       " '1850-09-21',\n",
       " '1543-12-23',\n",
       " '1894-11-07',\n",
       " '1909-07-21',\n",
       " '1764-09-09',\n",
       " '1641-06-13',\n",
       " '2038-07-06',\n",
       " '1547-06-22',\n",
       " '1869-05-08',\n",
       " '2012-11-17',\n",
       " '2004-03-19',\n",
       " '1896-05-25',\n",
       " '1790-08-24',\n",
       " '1815-08-17',\n",
       " '1904-02-03',\n",
       " '1714-11-05',\n",
       " '1559-01-15',\n",
       " '2001-03-26',\n",
       " '1592-02-17',\n",
       " '1599-04-07',\n",
       " '1813-07-25',\n",
       " '1541-09-21',\n",
       " '1829-06-02',\n",
       " '1841-07-11',\n",
       " '1734-01-22',\n",
       " '1547-11-25',\n",
       " '1638-08-27',\n",
       " '1918-08-21',\n",
       " '1990-03-27',\n",
       " '1578-04-09',\n",
       " '1641-12-07',\n",
       " '1813-08-27',\n",
       " '1685-06-21',\n",
       " '1819-02-12',\n",
       " '1651-04-19',\n",
       " '1537-11-07',\n",
       " '2068-11-24',\n",
       " '1800-07-07',\n",
       " '1742-08-16',\n",
       " '1846-01-20',\n",
       " '1570-06-04',\n",
       " '1986-12-18',\n",
       " '1533-01-16',\n",
       " '2054-01-13',\n",
       " '1570-03-18',\n",
       " '1809-03-07',\n",
       " '1844-11-09',\n",
       " '1897-12-11',\n",
       " '1524-08-17',\n",
       " '1595-10-12',\n",
       " '1929-01-07',\n",
       " '1920-11-09',\n",
       " '2045-02-01',\n",
       " '1766-02-03',\n",
       " '1602-12-08',\n",
       " '1670-09-18',\n",
       " '1593-01-18',\n",
       " '2066-10-18',\n",
       " '1878-08-05',\n",
       " '1788-01-04',\n",
       " '1740-02-24',\n",
       " '1997-04-10',\n",
       " '1885-07-02',\n",
       " '2061-12-10',\n",
       " '2040-02-11',\n",
       " '1778-07-07',\n",
       " '1803-07-29',\n",
       " '1720-08-29',\n",
       " '1705-10-07',\n",
       " '1771-01-24',\n",
       " '2063-02-02',\n",
       " '1620-02-15',\n",
       " '1598-08-08',\n",
       " '1629-02-04',\n",
       " '1971-04-11',\n",
       " '1841-01-18',\n",
       " '1736-07-13',\n",
       " '1791-09-20',\n",
       " '1984-09-19',\n",
       " '1865-06-05',\n",
       " '2011-03-19',\n",
       " '1853-03-13',\n",
       " '1758-06-12',\n",
       " '1840-10-08',\n",
       " '1953-12-31',\n",
       " '1577-06-13',\n",
       " '1739-03-13',\n",
       " '1524-08-18',\n",
       " '1617-07-29',\n",
       " '1547-11-06',\n",
       " '1708-08-03',\n",
       " '1940-12-30',\n",
       " '1908-08-01',\n",
       " '1556-06-14',\n",
       " '1589-05-24',\n",
       " '1911-06-14',\n",
       " '1551-03-26',\n",
       " '1847-08-29',\n",
       " '1656-04-21',\n",
       " '1817-04-28',\n",
       " '1895-08-08',\n",
       " '1726-03-23',\n",
       " '1954-09-27',\n",
       " '1888-06-24',\n",
       " '1550-06-07',\n",
       " '1766-04-19',\n",
       " '1585-07-15',\n",
       " '1952-03-18',\n",
       " '1999-09-10',\n",
       " '1597-11-02',\n",
       " '1835-08-05',\n",
       " '1723-10-21',\n",
       " '1744-12-31',\n",
       " '1944-09-09',\n",
       " '1836-12-28',\n",
       " '1633-08-23',\n",
       " '2046-11-21',\n",
       " '1912-07-02',\n",
       " '1540-09-22',\n",
       " '1586-06-21',\n",
       " '1620-12-10',\n",
       " '1679-08-31',\n",
       " '1871-07-23',\n",
       " '1756-02-28',\n",
       " '1928-05-08',\n",
       " '1862-08-18',\n",
       " '2047-11-09',\n",
       " '1585-07-13',\n",
       " '1780-05-18',\n",
       " '1970-07-16',\n",
       " '1924-03-31',\n",
       " '1663-12-26',\n",
       " '1926-11-01',\n",
       " '1917-11-24',\n",
       " '2070-08-18',\n",
       " '1890-01-01',\n",
       " '1763-03-24',\n",
       " '2060-08-03',\n",
       " '1969-02-08',\n",
       " '1734-05-08',\n",
       " '2045-09-08',\n",
       " '1905-10-17',\n",
       " '1969-04-23',\n",
       " '1580-07-16',\n",
       " '1533-08-21',\n",
       " '1614-05-08',\n",
       " '1864-09-26',\n",
       " '1904-11-22',\n",
       " '1941-09-09',\n",
       " '1981-09-03',\n",
       " '1901-05-25',\n",
       " '1527-06-02',\n",
       " '2028-09-29',\n",
       " '1708-07-26',\n",
       " '1674-02-08',\n",
       " '1818-10-29',\n",
       " '1974-01-04',\n",
       " '1569-01-20',\n",
       " '2017-07-31',\n",
       " '1559-09-24',\n",
       " '2040-11-27',\n",
       " '1880-08-11',\n",
       " '1965-10-05',\n",
       " '1759-06-28',\n",
       " '2068-09-03',\n",
       " '2030-11-06',\n",
       " '1613-02-14',\n",
       " '1556-08-05',\n",
       " '1582-09-19',\n",
       " '2059-11-15',\n",
       " '1761-04-20',\n",
       " '1726-10-08',\n",
       " '1605-11-26',\n",
       " '1593-02-02',\n",
       " '1959-03-30',\n",
       " '1834-12-23',\n",
       " '1747-05-01',\n",
       " '1749-07-02',\n",
       " '1747-03-28',\n",
       " '2042-06-21',\n",
       " '1936-06-02',\n",
       " '1717-02-22',\n",
       " '1641-08-22',\n",
       " '1758-11-09',\n",
       " '1877-08-02',\n",
       " '1681-11-08',\n",
       " '1625-03-15',\n",
       " '1609-12-20',\n",
       " '1873-10-24',\n",
       " '1895-03-14',\n",
       " '1851-04-23',\n",
       " '1534-03-20',\n",
       " '1886-12-11',\n",
       " '1673-08-01',\n",
       " '1845-04-10',\n",
       " '1755-06-28',\n",
       " '1803-12-27',\n",
       " '1838-07-13',\n",
       " '1918-01-06',\n",
       " '1710-04-01',\n",
       " '1767-10-14',\n",
       " '2007-05-25',\n",
       " '2003-10-01',\n",
       " '1850-02-26',\n",
       " '1728-05-23',\n",
       " '1608-08-15',\n",
       " '1848-09-30',\n",
       " '2051-04-22',\n",
       " '2055-08-14',\n",
       " '1560-03-15',\n",
       " '1555-02-19',\n",
       " '1998-01-13',\n",
       " '1961-11-27',\n",
       " '1563-03-12',\n",
       " '2064-06-08',\n",
       " '1787-04-05',\n",
       " '1978-11-05',\n",
       " '1978-01-18',\n",
       " '1841-01-14',\n",
       " '1656-03-30',\n",
       " '2017-12-23',\n",
       " '1876-07-15',\n",
       " '1997-04-11',\n",
       " '1609-05-31',\n",
       " '1652-02-03',\n",
       " '1791-12-17',\n",
       " '1915-01-08',\n",
       " '1825-02-28',\n",
       " '1524-04-13',\n",
       " '1530-08-27',\n",
       " '1904-03-07',\n",
       " '2001-03-09',\n",
       " '2050-05-31',\n",
       " '1708-02-14',\n",
       " '1945-04-07',\n",
       " '1992-01-30',\n",
       " '1933-07-14',\n",
       " '1624-11-02',\n",
       " '1895-11-27',\n",
       " '1824-11-04',\n",
       " '1691-11-22',\n",
       " '1658-02-02',\n",
       " '1550-10-02',\n",
       " '1616-10-17',\n",
       " '1670-08-21',\n",
       " '1791-01-31',\n",
       " '2029-03-03',\n",
       " '1835-09-02',\n",
       " '1985-01-31',\n",
       " '1941-08-24',\n",
       " '1797-09-14',\n",
       " '1699-11-09',\n",
       " '1841-04-24',\n",
       " '2066-08-26',\n",
       " '1642-12-11',\n",
       " '1757-10-23',\n",
       " '1829-07-19',\n",
       " '1889-12-03',\n",
       " '1962-07-16',\n",
       " '1914-01-03',\n",
       " '1585-01-29',\n",
       " '1899-09-28',\n",
       " '1670-12-28',\n",
       " '1871-09-12',\n",
       " '1736-02-01',\n",
       " '1684-08-30',\n",
       " '2031-11-07',\n",
       " '1967-05-04',\n",
       " '2059-09-07',\n",
       " '1847-07-28',\n",
       " '1550-11-19',\n",
       " '1734-08-02',\n",
       " '1658-09-22',\n",
       " '1733-03-17',\n",
       " '2071-09-16',\n",
       " '1607-04-17',\n",
       " '1570-08-05',\n",
       " '1973-03-27',\n",
       " '1774-10-05',\n",
       " '1773-07-11',\n",
       " '1880-03-25',\n",
       " '1553-11-03',\n",
       " '1745-05-14',\n",
       " '1639-10-29',\n",
       " '1884-06-20',\n",
       " '1621-05-13',\n",
       " '1916-11-28',\n",
       " '1826-11-10',\n",
       " '1610-08-29',\n",
       " '1948-11-19',\n",
       " '1775-07-09',\n",
       " '1752-10-01',\n",
       " '1847-06-14',\n",
       " '1932-06-18',\n",
       " '1918-11-10',\n",
       " '1626-08-27',\n",
       " '2050-12-23',\n",
       " '1786-11-13',\n",
       " '1881-06-28',\n",
       " '2059-01-04',\n",
       " '1559-04-17',\n",
       " '1868-03-27',\n",
       " '1593-10-12',\n",
       " '1799-11-04',\n",
       " '1987-01-19',\n",
       " '1984-07-10',\n",
       " '1751-09-08',\n",
       " '1992-07-27',\n",
       " '1741-09-12',\n",
       " '1873-11-07',\n",
       " '1943-11-07',\n",
       " '1585-02-13',\n",
       " '1781-10-04',\n",
       " '1533-01-22',\n",
       " '1743-01-15',\n",
       " '1793-12-11',\n",
       " '1820-02-15',\n",
       " '1584-04-08',\n",
       " '1579-06-21',\n",
       " '1609-02-12',\n",
       " '1757-12-02',\n",
       " '1532-09-20',\n",
       " '1801-03-22',\n",
       " '1730-08-04',\n",
       " '1710-03-27',\n",
       " '1962-08-15',\n",
       " '2020-02-14',\n",
       " '1956-05-25',\n",
       " '1666-05-30',\n",
       " '1936-04-04',\n",
       " '1628-12-06',\n",
       " '1692-08-11',\n",
       " '1872-06-17',\n",
       " '1955-02-28',\n",
       " '1752-10-31',\n",
       " '1901-01-14',\n",
       " '1593-03-06',\n",
       " '1654-01-11',\n",
       " '1879-10-17',\n",
       " '1565-07-04',\n",
       " '1700-06-04',\n",
       " '1682-10-28',\n",
       " '1566-04-15',\n",
       " '1651-01-30',\n",
       " '1693-02-24',\n",
       " '2071-06-07',\n",
       " '1837-09-17',\n",
       " '2047-02-01',\n",
       " '1979-05-21',\n",
       " '1557-07-22',\n",
       " '1808-11-19',\n",
       " '1567-04-20',\n",
       " '1565-03-21',\n",
       " '1529-01-13',\n",
       " '1546-09-09',\n",
       " '1705-09-06',\n",
       " '2049-01-15',\n",
       " '1654-10-10',\n",
       " '1724-05-11',\n",
       " '1990-07-21',\n",
       " '1943-10-26',\n",
       " '1723-09-10',\n",
       " '1874-06-12',\n",
       " '1838-10-13',\n",
       " '1981-04-26',\n",
       " '1564-05-31',\n",
       " '1932-12-28',\n",
       " '1925-09-21',\n",
       " '2023-05-20',\n",
       " '1785-09-21',\n",
       " '1608-01-23',\n",
       " '1569-12-30',\n",
       " '1644-03-31',\n",
       " '1827-02-17',\n",
       " '1882-01-25',\n",
       " '1758-12-28',\n",
       " '2053-11-16',\n",
       " '2050-06-11',\n",
       " '1997-05-03',\n",
       " '1924-06-01',\n",
       " '1921-11-16',\n",
       " '1962-12-22',\n",
       " '1736-03-26',\n",
       " '1912-06-21',\n",
       " '1639-07-01',\n",
       " '1864-10-01',\n",
       " '1777-12-27',\n",
       " '1974-07-23',\n",
       " '1668-02-01',\n",
       " '1705-01-08',\n",
       " '1667-07-17',\n",
       " '1800-02-25',\n",
       " '1726-11-15',\n",
       " '1561-03-13',\n",
       " '2063-03-28',\n",
       " '1620-02-18',\n",
       " '1635-06-06',\n",
       " '1885-09-12',\n",
       " '1941-07-23',\n",
       " '1839-12-08',\n",
       " '1802-05-14',\n",
       " '1636-04-19',\n",
       " '1830-02-21',\n",
       " '1770-03-22',\n",
       " '1671-02-10',\n",
       " '1831-05-20',\n",
       " '1907-11-11',\n",
       " '1904-06-26',\n",
       " '1620-11-06',\n",
       " '1891-10-03',\n",
       " '1849-04-22',\n",
       " '1646-01-17',\n",
       " '1756-11-21',\n",
       " '1707-03-15',\n",
       " '1985-12-30',\n",
       " '1575-09-14',\n",
       " '1965-08-21',\n",
       " '2023-10-18',\n",
       " '1628-11-28',\n",
       " '1591-08-23',\n",
       " '1864-02-05',\n",
       " '1930-07-25',\n",
       " '2029-11-06',\n",
       " '1810-02-16',\n",
       " '1730-05-29',\n",
       " '1739-12-06',\n",
       " '1681-08-06',\n",
       " '1726-08-27',\n",
       " '1552-01-21',\n",
       " '1890-06-14',\n",
       " '1679-10-04',\n",
       " '1647-10-22',\n",
       " '1951-08-12',\n",
       " '1590-11-14',\n",
       " '1632-01-29',\n",
       " '1570-11-25',\n",
       " '1619-11-20',\n",
       " '1886-06-12',\n",
       " '2060-07-18',\n",
       " '1944-07-12',\n",
       " '1592-04-11',\n",
       " '1749-12-06',\n",
       " '1893-08-22',\n",
       " '1536-03-29',\n",
       " '2063-05-07',\n",
       " '2013-01-06',\n",
       " '1760-02-17',\n",
       " '2045-09-25',\n",
       " '1876-03-25',\n",
       " '1998-08-06',\n",
       " '1715-08-18',\n",
       " '1978-10-04',\n",
       " '2011-01-27',\n",
       " '1803-04-08',\n",
       " '1888-02-14',\n",
       " '1761-06-20',\n",
       " '1535-11-22',\n",
       " '1967-09-05',\n",
       " '2033-08-01',\n",
       " '1629-12-19',\n",
       " '1983-06-14',\n",
       " '1717-01-04',\n",
       " '1633-05-03',\n",
       " '1980-06-22',\n",
       " '2066-08-16',\n",
       " '1854-01-28',\n",
       " '1989-11-09',\n",
       " '2018-03-12',\n",
       " '1930-09-13',\n",
       " '1804-08-21',\n",
       " '1642-09-21',\n",
       " '1781-06-07',\n",
       " '1558-10-31',\n",
       " '1599-01-10',\n",
       " '1843-10-16',\n",
       " '1902-06-22',\n",
       " '1665-05-08',\n",
       " '1544-10-06',\n",
       " '1524-08-11',\n",
       " '1687-09-18',\n",
       " '1897-05-12',\n",
       " '1908-08-22',\n",
       " '1892-06-04',\n",
       " '1644-10-21',\n",
       " '1591-10-05',\n",
       " '1677-02-08',\n",
       " '1522-11-29',\n",
       " '1865-03-12',\n",
       " '1984-02-16',\n",
       " '1547-02-18',\n",
       " '1722-09-27',\n",
       " '1646-01-29',\n",
       " '1779-03-09',\n",
       " '1982-03-31',\n",
       " '1918-02-28',\n",
       " '2027-01-02',\n",
       " '1728-05-19',\n",
       " '1707-11-18',\n",
       " '1868-09-28',\n",
       " '1803-11-05',\n",
       " '1526-07-17',\n",
       " '1567-09-24',\n",
       " '1774-07-24',\n",
       " '1907-01-15',\n",
       " '1615-02-13',\n",
       " '1978-09-07',\n",
       " '2001-08-13',\n",
       " '2015-04-01',\n",
       " '1757-04-19',\n",
       " '1565-07-31',\n",
       " '1892-02-02',\n",
       " '1827-01-14',\n",
       " '1960-04-09',\n",
       " '1803-07-10',\n",
       " '1650-02-23',\n",
       " '1901-03-04',\n",
       " '1757-01-21',\n",
       " '1682-04-20',\n",
       " '1569-10-04',\n",
       " '1855-01-21',\n",
       " '2044-10-01',\n",
       " '1696-06-05',\n",
       " '2067-01-03',\n",
       " '1707-11-28',\n",
       " '1872-06-09',\n",
       " '1974-03-08',\n",
       " '1909-02-25',\n",
       " '1580-12-22',\n",
       " '1889-04-12',\n",
       " '1871-05-19',\n",
       " '1661-09-28',\n",
       " '1683-12-13',\n",
       " '1690-11-10',\n",
       " '1699-04-04',\n",
       " '2070-10-23',\n",
       " '1869-01-07',\n",
       " '1679-12-20',\n",
       " '1689-12-29',\n",
       " '1842-04-22',\n",
       " '1993-02-18',\n",
       " '1581-08-15',\n",
       " '1842-10-13',\n",
       " '1735-07-24',\n",
       " '1828-05-04',\n",
       " '1608-09-14',\n",
       " '2058-06-26',\n",
       " '1552-09-27',\n",
       " '1625-02-09',\n",
       " '1660-11-24',\n",
       " '1597-11-27',\n",
       " '1624-04-17',\n",
       " '2011-11-15',\n",
       " '1556-09-08',\n",
       " '1708-04-19',\n",
       " '1570-10-03',\n",
       " '1743-10-17',\n",
       " '1601-09-06',\n",
       " '1797-01-23',\n",
       " '1598-08-05',\n",
       " '1874-12-07',\n",
       " '1994-01-05',\n",
       " '1723-07-23',\n",
       " '1620-03-07',\n",
       " '1820-11-20',\n",
       " '1771-07-10',\n",
       " '1548-07-17',\n",
       " '2003-06-29',\n",
       " '1795-12-25',\n",
       " '2063-10-14',\n",
       " '1587-08-25',\n",
       " '1653-07-30',\n",
       " '1886-06-01',\n",
       " '1805-10-22',\n",
       " '1776-10-24',\n",
       " '1571-12-26',\n",
       " '1610-12-10',\n",
       " '2000-05-09',\n",
       " '1823-11-29',\n",
       " '1869-11-29',\n",
       " '1957-02-06',\n",
       " '1638-10-09',\n",
       " '1702-09-05',\n",
       " '1999-09-03',\n",
       " '1538-05-08',\n",
       " '1786-09-14',\n",
       " '1970-01-10',\n",
       " '1792-04-13',\n",
       " '1743-01-24',\n",
       " '1578-07-30',\n",
       " '1573-04-13',\n",
       " '2054-03-11',\n",
       " '1976-04-03',\n",
       " '1686-04-29',\n",
       " '1927-07-02',\n",
       " '1534-07-29',\n",
       " '1841-09-02',\n",
       " '1948-01-08',\n",
       " '2019-10-01',\n",
       " '1745-05-09',\n",
       " '1992-05-23',\n",
       " '1760-05-31',\n",
       " '2011-11-22',\n",
       " '2013-08-20',\n",
       " '2035-05-24',\n",
       " '1680-10-29',\n",
       " '1805-06-04',\n",
       " '1717-08-07',\n",
       " '2022-09-02',\n",
       " '1972-04-18',\n",
       " '2034-11-06',\n",
       " '1578-01-13',\n",
       " '2058-12-20',\n",
       " '1993-01-31',\n",
       " '2026-07-24',\n",
       " '1797-09-25',\n",
       " '1556-02-09',\n",
       " '1916-04-25',\n",
       " '2002-10-09',\n",
       " '1694-03-15',\n",
       " '2024-12-11',\n",
       " '1787-12-21',\n",
       " '2017-04-26',\n",
       " '1917-05-15',\n",
       " '2046-02-02',\n",
       " '1733-05-03',\n",
       " '1754-12-10',\n",
       " '1841-07-23',\n",
       " '1587-05-30',\n",
       " '1523-09-14',\n",
       " '1735-03-10',\n",
       " '1729-07-12',\n",
       " '2011-07-31',\n",
       " '1661-07-18',\n",
       " '1928-02-11',\n",
       " '1832-01-28',\n",
       " '1932-08-13',\n",
       " '1599-11-09',\n",
       " '1641-07-09',\n",
       " '2045-10-14',\n",
       " '1893-04-13',\n",
       " '1538-07-04',\n",
       " '1811-11-07',\n",
       " '1615-03-28',\n",
       " '1912-04-19',\n",
       " '2062-07-31',\n",
       " '1654-02-10',\n",
       " '2006-06-18',\n",
       " '1971-12-03',\n",
       " '1815-05-29',\n",
       " '1731-07-19',\n",
       " '1886-06-05',\n",
       " '1713-01-08',\n",
       " '1689-04-30',\n",
       " '2026-07-04',\n",
       " '1939-01-23',\n",
       " '2042-06-29',\n",
       " '1941-03-26',\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_actual_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excat matches  9589\n",
      "Less than 10  6\n"
     ]
    }
   ],
   "source": [
    "# now the actual predicted outputs are saved in the file, now we can calculate the errors\n",
    "test_exact_match_error, test_mismatch_error, test_highest_error, test_lowest_error = calculate_all_errors(test_actual_outputs, test_predicted_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Error: 95.89\n",
      "Mismatch Error: 0.511\n",
      "Highest Error: 2\n",
      "Lowest Error: 5\n"
     ]
    }
   ],
   "source": [
    "print('Exact Match Error:', test_exact_match_error)\n",
    "print('Mismatch Error:', test_mismatch_error)\n",
    "print('Highest Error:', test_highest_error)\n",
    "print('Lowest Error:', test_lowest_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLNLP_A1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
